# NutriPal â€” Client Requirements Gap Analysis

> **Date**: 2026-02-24  
> **Scope**: Comparison of the two client spec documents ("Features and behavior.md" + "client Request .md") against the live codebase.  
> **Verdict**: Read-only audit â€” no code changes.

---

## Scoring Legend

| Rating | Meaning |
|--------|---------|
| âœ… **Shipped** | Feature is implemented and working |
| ðŸŸ¡ **Partial** | Core mechanics exist but the spec's full intent is not met |
| âŒ **Missing** | No implementation found in codebase |

---

## 1. Totals + Transparency (Auditability)

| Sub-requirement | Status | Evidence |
|---|---|---|
| Per-item nutrition breakdown shown to user | âœ… | PCC pattern in orchestrator shows `nutrition` array in `confirmation_food_log` responses; UI renders confirmation cards |
| Running totals visible | âœ… | `get_today_progress` tool aggregates daily totals; dashboard page displays them |
| Delta to targets | âœ… | `DashboardSummaryTable.tsx` computes goal progress percentages with color-coded thresholds |
| Internal sanity checks | âœ… | `ValidatorAgent` checks calorie-macro consistency, outlier detection, zero-calorie guards |
| Surface raw math even when disagreeing | ðŸŸ¡ | Validator warnings are logged but **not always surfaced to the user** in the chat response â€” the ChatAgent may summarize without showing the numbers |

**Gap**: The spec says "never output a conclusion without the numbers behind it." The current `ChatAgent` prompt says "Never use bullet points for nutrition data. The UI handles that." â€” this can result in chat responses that give advice without showing math when no confirmation card is present (e.g., advisory queries).

---

## 2. Ambiguity Detection + Clarification

| Sub-requirement | Status | Evidence |
|---|---|---|
| Detect unclear portions, homemade vs restaurant, cooking methods | ðŸŸ¡ | No dedicated ambiguity-detection pass. The system relies on the `ReasoningAgent` (GPT-4o) to decide whether to ask. There is no **structured** ambiguity triage |
| Ask 1â€“2 clarifying questions max | ðŸŸ¡ | No hard limit enforced in prompts. GPT-4o can ask as many or as few questions as it decides |
| Label assumptions explicitly if proceeding | ðŸŸ¡ | Nutrition estimates include a `confidence` field internally, but it is **not consistently surfaced** to the user as "I'm assuming X because Y" |
| No silent defaults | ðŸŸ¡ | The `IntentAgent` extracts portions with a default of `"1 serving"` (line 290 orchestrator) â€” a silent default |

**Gap**: Ambiguity awareness exists but is **ad-hoc** (depends on LLM initiative) rather than **systematic** (a dedicated detection pass before estimation). The spec demands "Ambiguity beats speed" â€” the current design prioritizes speed (fast-paths bypass reasoning for single items).

---

## 3. Error Awareness & Uncertainty as First-Class Output

| Sub-requirement | Status | Evidence |
|---|---|---|
| Confidence level on every estimate | ðŸŸ¡ | `batch-calculator.ts`, `serving-detector.ts`, and `nutrition-agent.ts` compute `confidence: 'low' | 'medium' | 'high'`. But this is **internal only** â€” the confidence is not rendered to the user in the chat message or the confirmation card UI |
| Top 1â€“2 likely error sources surfaced | âŒ | No implementation. Error sources are not listed |
| False precision avoided | ðŸŸ¡ | Values are rounded, but estimates are presented as exact numbers rather than ranges |

**Gap**: The internal machinery computes confidence, but **none of it reaches the user**. This is the single largest gap against the spec, which calls uncertainty a "first-class output." Error sources (restaurant oils, portion ambiguity, label vs. prepared) are never surfaced.

---

## 4. Corrections Persist as Memory (Learning System)

| Sub-requirement | Status | Evidence |
|---|---|---|
| User corrections override defaults | ðŸŸ¡ | `SessionService.addUserCorrection()` stores corrections in the session buffer (last 10) |
| Corrections cached and reused automatically | âŒ | Corrections are stored but **never read back**. No code queries the `userCorrections` buffer to influence future estimates |
| System confirms "I'll treat this as source of truth" | âŒ | No such confirmation text in any agent prompt |

**Gap**: The persistence layer exists but the **retrieval and re-application loop is missing**. User corrections vanish after the session buffer scrolls past them.

---

## 5. Planning Is First-Class (What-If Engine)

| Sub-requirement | Status | Evidence |
|---|---|---|
| "If I eat this, where does that put me?" | ðŸŸ¡ | `ReasoningAgent` can call `get_today_progress` + `lookup_nutrition` to answer this, but it is **not a structured mode** â€” it relies on the LLM stitching the answer together |
| Branching scenarios | âŒ | No scenario storage, no branching logic, no planned-vs-actual comparison |
| Planning mode vs. logging mode | âŒ | There is only one mode (logging). No explicit planning mode exists |
| Counterfactuals ("if I hadn't eaten that snackâ€¦") | âŒ | No implementation |

**Gap**: The spec calls this a "what-if engine, not a diary." The current system is fundamentally a **diary** with advisory capabilities. There is no scenario branching, no planned intake, and no counterfactual reasoning.

---

## 6. Time + Timezone Awareness

| Sub-requirement | Status | Evidence |
|---|---|---|
| Timestamp on every entry | âœ… | `log_time` is set on every food log entry |
| Timezone awareness | âœ… | `timezone` is threaded through the entire orchestrator â†’ agents â†’ tools chain |
| Reasoning about "earlier today," "late-night," etc. | ðŸŸ¡ | Time data is available to the `ReasoningAgent`, but there is **no prompt guidance** instructing it to reason temporally. No "late-night eating" detection |
| Daily boundary logic | âœ… | `getStartAndEndOfDay()` utility handles timezone-aware day boundaries |

**Gap**: Infrastructure is solid. The missing piece is **temporal reasoning prompts and pattern detection** tied to time-of-day.

---

## 7. Triage Logic (What Matters Now)

| Sub-requirement | Status | Evidence |
|---|---|---|
| Rank today's priorities when goals conflict | âŒ | No triage logic. The system presents all goals with equal weight |
| Say what can be ignored | âŒ | Not implemented |
| Identify one lever worth pulling | âŒ | Not implemented |
| Special handling for late nights, travel, depleted states | âŒ | No day-state awareness (see Â§11) |

**Gap**: Entirely missing. The system treats every goal as equally important regardless of context.

---

## 8. Tradeoff Reasoning (Multi-Objective Arbitration)

| Sub-requirement | Status | Evidence |
|---|---|---|
| Reason across protein vs sodium, calories vs hunger, etc. | âŒ | No tradeoff reasoning in any agent prompt |
| Make a recommendation tied to today | âŒ | Recommendations exist (`get_food_recommendations`) but are generic, not conflict-aware |
| Include confidence and uncertainty | âŒ | See Â§3 |

**Gap**: Entirely missing. The spec says "No 'just facts' cop-outs." Current behavior is purely fact-driven.

---

## 9. Cognitive Load Reduction (Summary Format)

| Sub-requirement | Status | Evidence |
|---|---|---|
| Bullets only, 3â€“5 max | ðŸŸ¡ | `InsightAgent` prompt says "Keep it under 40 words total" but does **not enforce** bullet format |
| Summary answers: what mattered, what didn't, takeaway, adjustment | ðŸŸ¡ | `InsightAgent` asks for "2 very short suggestions" â€” not aligned with the spec's 4-part structure |
| No moral tone, no essays | ðŸŸ¡ | Not enforced in prompts. `ChatAgent` says "encouraging" which can drift toward moral tone |
| Weekly summary | âœ… | `get_weekly_summary` tool exists and is called by `ReasoningAgent` |

**Gap**: Summaries exist but don't follow the spec's hard format rules. The current prompt produces free-form suggestions, not the structured "what mattered / what didn't / takeaway / adjustment" format.

---

## 10. Negotiation Stance (Not Authority)

| Sub-requirement | Status | Evidence |
|---|---|---|
| Pragmatic, constraint-aware tone | ðŸŸ¡ | `ChatAgent` prompt says "friendly and professional" and "encouraging." This is closer to **coach** than **negotiation partner** |
| No "you should have," "ideally," "best practice" | âŒ | Not enforced. No negative-pattern instructions in prompts |
| Comfortable with "good enough" | âŒ | Not addressed in any prompt |

**Gap**: The tone is "friendly nutrition coach" â€” the spec explicitly says it should **not** be a coach. It should be a "pragmatic decision partner." The prompt language needs a rewrite.

---

## 11. Exception Handling & Day Classification

| Sub-requirement | Status | Evidence |
|---|---|---|
| Detect travel / sick / workout / social / depleted days | âŒ | No day classification system. No DB table for day types |
| Adjust expectations for exceptional days | âŒ | No implementation. `apply_daily_workout_offset` handles workouts only as calorie bonuses, not as day reclassification |
| Avoid silent penalties | âŒ | Goal thresholds are static; a travel day is penalized the same as a normal day |

**Gap**: Entirely missing. The spec treats this as critical: "Exceptions are categories, not failures."

---

## 12. Audit Mode (Model Debugging)

| Sub-requirement | Status | Evidence |
|---|---|---|
| When user says "this seems off," surface undercount sources | âŒ | No audit-mode intent or handler. "This seems off" would route to `ReasoningAgent` with no specific prompt guidance |
| Discuss uncertainty explicitly | âŒ | See Â§3 |
| Ask minimal clarifying questions | âŒ | No audit-specific logic |

**Gap**: Entirely missing. The spec says treat this as "debugging the model, not correcting the user." No code supports this.

---

## 13. Reflection Loops (Post-Hoc Insight)

| Sub-requirement | Status | Evidence |
|---|---|---|
| Top contributors today | ðŸŸ¡ | `InsightAgent` computes daily totals and can surface top items, but doesn't explicitly list "top contributors" |
| What changed vs yesterday | âŒ | No day-over-day comparison tool |
| Single biggest improvement lever | âŒ | Not implemented |
| Pattern vs noise judgment | âŒ | Not implemented |

**Gap**: `InsightAgent` provides basic suggestions but **not** the structured retrospective the spec requires.

---

## 14. Longitudinal Pattern Interpretation

| Sub-requirement | Status | Evidence |
|---|---|---|
| "This keeps happening" | âŒ | No recurring-pattern detection. `analyze_eating_patterns` exists as a tool definition but the implementation (in `ToolExecutor`) just returns raw data; no interpretation layer |
| "This is new" | âŒ | No novelty detection |
| "This only happens under condition X" | âŒ | No conditional pattern analysis (would require day classification from Â§11) |
| Proactive pattern recognition (unprompted) | âŒ | Nothing triggers pattern analysis automatically |

**Gap**: The tool infrastructure (`analyze_eating_patterns`, `get_progress_report`) exists, but it returns raw aggregates without the **interpretive layer** the spec demands.

---

## Anti-Patterns Check

| Anti-pattern | Status |
|---|---|
| No silent guessing | ðŸŸ¡ â€” Default "1 serving" is a silent assumption |
| No red-badge / guilt framing without context | ðŸŸ¡ â€” Dashboard uses red/yellow/green but context is limited to threshold math |
| No treatises in summaries | ðŸŸ¡ â€” `InsightAgent` prompt is short, but `ChatAgent` responses can be lengthy |
| No one-size-fits-all recommendations | âŒ â€” No personalization beyond goals |
| No "remaining macros" as primary response when user is stressed | âŒ â€” No stress/context detection |

---

## Acceptance Test Readiness

| Test | Pass? |
|---|---|
| "A bowl of pasta" â†’ asks 1â€“2 clarifiers or proceeds with explicit assumptions + low confidence | âŒ â€” Currently looks up nutrition silently with default portion |
| "Was today fine?" â†’ 3â€“5 bullets, no essay | ðŸŸ¡ â€” Could produce bullets via reasoning, but no format enforcement |
| "Worth it?" tradeoff â†’ decision + rationale + uncertainty | âŒ â€” No tradeoff engine |
| "Travel day, no control" â†’ reclassifies day and changes expectations | âŒ â€” No day classification |
| "This seems wrong" â†’ lists top error sources and asks minimal clarifiers | âŒ â€” No audit mode |

---

## Summary Scorecard

| Requirement Area | Score |
|---|---|
| 1. Totals + Transparency | **85%** âœ… |
| 2. Ambiguity Detection | **30%** ðŸŸ¡ |
| 3. Uncertainty as Output | **15%** ðŸŸ¡ |
| 4. Corrections Persist | **20%** ðŸŸ¡ |
| 5. What-If / Planning | **10%** âŒ |
| 6. Time Awareness | **70%** âœ… |
| 7. Triage Logic | **0%** âŒ |
| 8. Tradeoff Reasoning | **0%** âŒ |
| 9. Summary Format | **40%** ðŸŸ¡ |
| 10. Negotiation Tone | **20%** ðŸŸ¡ |
| 11. Day Classification | **0%** âŒ |
| 12. Audit Mode | **0%** âŒ |
| 13. Reflection Loops | **15%** ðŸŸ¡ |
| 14. Longitudinal Patterns | **5%** âŒ |

### Overall Alignment: **~22%**

> The app has a strong **logging and recipe management** foundation (PCC pattern, validation, recipes, goals, dashboard) but the **reasoning, uncertainty, planning, and contextual intelligence** layers that define the client's vision are largely absent. The system currently behaves as a **nutrition diary with an AI lookup**, not the **"auditable, stateful, scenario-aware thinking partner"** the client specified.

---

## Highest-Impact Gaps (Recommended Priority Order)

1. **Uncertainty & Confidence surfaced to user** (Â§3) â€” data exists internally, just needs to flow to UI
2. **Ambiguity detection pass** (Â§2) â€” a pre-estimation check before silent defaults
3. **Day classification system** (Â§11) â€” enables Â§7, Â§8, Â§14
4. **Prompt tone overhaul** (Â§10) â€” negotiation partner, not coach
5. **Summary format enforcement** (Â§9) â€” structured bullets, not free-form
6. **Audit mode** (Â§12) â€” "this seems off" handler
7. **Tradeoff reasoning** (Â§8) â€” multi-objective arbitration
8. **What-if engine** (Â§5) â€” branching scenarios and planning mode
9. **Corrections reuse loop** (Â§4) â€” read back stored corrections
10. **Longitudinal pattern interpretation** (Â§14) â€” interpretive layer on top of raw data
